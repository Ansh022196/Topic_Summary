{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDhTuxhZyVJe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import  numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from  nltk.tokenize import sent_tokenize\n",
        "from textblob import TextBlob\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise  import cosine_similarity\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn import preprocessing\n",
        "import sys\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as BeautifulSoup\n",
        "import urllib.request  \n",
        "\n",
        "fetched_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Electric_vehicle')\n",
        "article_read = fetched_data.read()\n",
        "article_parsed = BeautifulSoup.BeautifulSoup(article_read,'html.parser')\n",
        "paragraphs = article_parsed.find_all('p')\n",
        "article_content = ''\n",
        "# Looping through the paragraphs and adding them to the variable\n",
        "for p in paragraphs:  \n",
        "    article_content += p.text"
      ],
      "metadata": {
        "id": "UTF583w56oE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetched_data_P = urllib.request.urlopen('https://e-amrit.niti.gov.in/benefits-of-electric-vehicles')\n",
        "article_read_p = fetched_data_P.read()\n",
        "article_parsed_p = BeautifulSoup.BeautifulSoup(article_read_p,'html.parser')\n",
        "paragraphs_p = article_parsed_p.find_all('p')\n",
        "article_content_p = ''\n",
        "# Looping through the paragraphs and adding them to the variable\n",
        "for p in paragraphs_p:  \n",
        "    article_content_p += p.text\n"
      ],
      "metadata": {
        "id": "-rA_7tqb7Cgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fetched_data_n = urllib.request.urlopen('https://ypte.org.uk/factsheets/electric-cars/what-are-the-downsides-to-electric-cars')\n",
        "article_read_n = fetched_data_n.read()\n",
        "article_parsed_n = BeautifulSoup.BeautifulSoup(article_read_n,'html.parser')\n",
        "paragraphs_n = article_parsed_n.find_all('p')\n",
        "article_content_n = ''\n",
        "# Looping through the paragraphs and adding them to the variable\n",
        "for p in paragraphs_n:  \n",
        "    article_content_n += p.text\n"
      ],
      "metadata": {
        "id": "eJ6TsLLVWNdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_content_n"
      ],
      "metadata": {
        "id": "Htjz2Rej9Zov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus=article_content+article_content_n+article_content_p+data\n",
        "len(combine_corpus)"
      ],
      "metadata": {
        "id": "8oUI3zJtWoTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus #  n"
      ],
      "metadata": {
        "id": "OUM1lmAQWoVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/FinalSummary.txt','r') as  file:\n",
        "  data=file.read().rstrip('\\n')\n"
      ],
      "metadata": {
        "id": "J7KXYLTal0r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus"
      ],
      "metadata": {
        "id": "qaVytKI8l2Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus=combine_corpus.lower()\n",
        "combine_corpus"
      ],
      "metadata": {
        "id": "3F-FvgjBl2RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "exclude=punctuation+'\\n'+'\\t'+'\\r'+'\\xa0'"
      ],
      "metadata": {
        "id": "r-NcxD-Ml2Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus = combine_corpus.translate(str.maketrans('', '', exclude))"
      ],
      "metadata": {
        "id": "Sdbz7KL6l2YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus"
      ],
      "metadata": {
        "id": "1MSLGfMil2j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_corpus=combine_corpus.rstrip()\n",
        "combine_corpus"
      ],
      "metadata": {
        "id": "3GpDGEZ6l2s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize                    import word_tokenize"
      ],
      "metadata": {
        "id": "ZPvr63VK9ZsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords=nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "8wayv0kuAlIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeWords(lot,stopwords):\n",
        "  return [token for token in lot if not token in stopwords]\n"
      ],
      "metadata": {
        "id": "-4RVHk7a9Zv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lot=removeWords(lot,stopwords)"
      ],
      "metadata": {
        "id": "yeIJqCf-BMHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "doc=nlp(combine_corpus)"
      ],
      "metadata": {
        "id": "Lax4LwP4B-CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies={}\n",
        "for word in doc:\n",
        "  if word.text.lower() not  in stopwords:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequencies.keys():\n",
        "        word_frequencies[word.text]=1\n",
        "      else:\n",
        "        word_frequencies[word.text]+=1\n",
        "\n"
      ],
      "metadata": {
        "id": "qGf5zi2kB-EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "id": "gc-wP94ODqSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf =max(word_frequencies.values())"
      ],
      "metadata": {
        "id": "T_dNGqwKEG8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word]=word_frequencies[word]/mf"
      ],
      "metadata": {
        "id": "5gvHQdW3EekM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies"
      ],
      "metadata": {
        "id": "GteeqnvEFGCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uvGBhCvFuz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize=[sent for sent in doc.sents]\n",
        "print(sent_tokenize)"
      ],
      "metadata": {
        "id": "hp2gfvTcFu_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_score={}\n",
        "for sent in sent_tokenize:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent  not in sentences_score.keys():\n",
        "        sentences_score[sent]=word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "        sentences_score[sent]=word_frequencies[word.text.lower()]"
      ],
      "metadata": {
        "id": "0f0GN0zXF29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_score"
      ],
      "metadata": {
        "id": "xGze5qozF2_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now  we have  our aim to  select the top  30%  of the sentences so that we can do  the  following things\n",
        "from heapq import nlargest"
      ],
      "metadata": {
        "id": "5MwcR33uF3Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary=nlargest(select_length,sentences_score,key=sentences_score.get)"
      ],
      "metadata": {
        "id": "5m894XYRxXEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "select_length=int(len(sent_tokenize)*0.3)"
      ],
      "metadata": {
        "id": "ndRRgCMBw6yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ele=\"\""
      ],
      "metadata": {
        "id": "CEM2ENygsm0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in  summary:\n",
        "  ele+=i.text"
      ],
      "metadata": {
        "id": "NERfFxLRsjdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "i-FaWSLdwUdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = re.sub(' +', ' ', ele)"
      ],
      "metadata": {
        "id": "JK2HvlersteU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "GPxkM1x5wXHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "these are the  steps to generate  word  cloud in python with the  help of the twitter and the you tube data\n"
      ],
      "metadata": {
        "id": "3WS60u813Rua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud  import WordCloud\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EJiKqrfu3bPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SqtuEkNsiyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cloud=WordCloud()"
      ],
      "metadata": {
        "id": "FIhNL0lC4QUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(summary)"
      ],
      "metadata": {
        "id": "shB72o8H5MzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cloud=cloud.generate(res)"
      ],
      "metadata": {
        "id": "MttYT2cr47VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cloud)"
      ],
      "metadata": {
        "id": "4STeE6OdJ5jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(cloud)\n",
        "plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "wupauSa5KFPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97BQI85yOFAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNTIx9HrLAcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}